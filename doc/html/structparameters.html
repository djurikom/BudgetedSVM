<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.18"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>BudgetedSVM: parameters Struct Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="budgetedSVM.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">BudgetedSVM
   &#160;<span id="projectnumber">1.2</span>
   </div>
   <div id="projectbrief">BudgetedSVM: A C++ Toolbox for Large-scale, Non-linear Classification</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.18 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="structparameters-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">parameters Struct Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Structure holds the parameters of the implemented algorithms.  
 <a href="structparameters.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a41e1c196acc4a9969c7eb796b38ef685"><td class="memItemLeft" align="right" valign="top"><a id="a41e1c196acc4a9969c7eb796b38ef685"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a41e1c196acc4a9969c7eb796b38ef685">parameters</a> (void)</td></tr>
<tr class="memdesc:a41e1c196acc4a9969c7eb796b38ef685"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor of the structure. The default values of the parameters can be modified here manually. <br /></td></tr>
<tr class="separator:a41e1c196acc4a9969c7eb796b38ef685"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4950eb95f9a5ab221bb7f6b040546ee8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a4950eb95f9a5ab221bb7f6b040546ee8">updateVerySparseDataParameter</a> (double dataSparsity)</td></tr>
<tr class="memdesc:a4950eb95f9a5ab221bb7f6b040546ee8"><td class="mdescLeft">&#160;</td><td class="mdescRight">If <a class="el" href="structparameters.html#aa3c969ce30b1b163bfa1ff0d6b6ed0dd">VERY_SPARSE_DATA</a> parameter was not set by a user, this function sets this parameter according to the sparsity of the loaded data.  <a href="structparameters.html#a4950eb95f9a5ab221bb7f6b040546ee8">More...</a><br /></td></tr>
<tr class="separator:a4950eb95f9a5ab221bb7f6b040546ee8"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a6f73698e71821702511be796b7d93140"><td class="memItemLeft" align="right" valign="top"><a id="a6f73698e71821702511be796b7d93140"></a>
unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a6f73698e71821702511be796b7d93140">ALGORITHM</a></td></tr>
<tr class="memdesc:a6f73698e71821702511be796b7d93140"><td class="mdescLeft">&#160;</td><td class="mdescRight">Algorithm that is used, 0 - Pegasos; 1 - AMM batch; 2 - AMM online; 3 - LLSVM; 4 - BSGD (default: 2) <br /></td></tr>
<tr class="separator:a6f73698e71821702511be796b7d93140"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b41d4a23975df18a08aba2869c723ab"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a7b41d4a23975df18a08aba2869c723ab">NUM_SUBEPOCHS</a></td></tr>
<tr class="memdesc:a7b41d4a23975df18a08aba2869c723ab"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of training subepochs of AMM batch algorithm (default: 1)  <a href="structparameters.html#a7b41d4a23975df18a08aba2869c723ab">More...</a><br /></td></tr>
<tr class="separator:a7b41d4a23975df18a08aba2869c723ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a5d9f4f2ac435cb56ecc0bd879977d5"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a7a5d9f4f2ac435cb56ecc0bd879977d5">NUM_EPOCHS</a></td></tr>
<tr class="memdesc:a7a5d9f4f2ac435cb56ecc0bd879977d5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of training epochs (default: 5)  <a href="structparameters.html#a7a5d9f4f2ac435cb56ecc0bd879977d5">More...</a><br /></td></tr>
<tr class="separator:a7a5d9f4f2ac435cb56ecc0bd879977d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae071568a10354aa235e31ff10fd042d6"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#ae071568a10354aa235e31ff10fd042d6">K_PARAM</a></td></tr>
<tr class="memdesc:ae071568a10354aa235e31ff10fd042d6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Frequency k of weight pruning of AMM algorithms (default: 10,000 iterations)  <a href="structparameters.html#ae071568a10354aa235e31ff10fd042d6">More...</a><br /></td></tr>
<tr class="separator:ae071568a10354aa235e31ff10fd042d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9070068c869e6665c4fe04bd6a8d1b15"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a9070068c869e6665c4fe04bd6a8d1b15">DIMENSION</a></td></tr>
<tr class="memdesc:a9070068c869e6665c4fe04bd6a8d1b15"><td class="mdescLeft">&#160;</td><td class="mdescRight">Dimensionality of the classification problem, MUST be set by a user (default: 0)  <a href="structparameters.html#a9070068c869e6665c4fe04bd6a8d1b15">More...</a><br /></td></tr>
<tr class="separator:a9070068c869e6665c4fe04bd6a8d1b15"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b93563370dd18a3e6cf83bca149a661"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a6b93563370dd18a3e6cf83bca149a661">CHUNK_SIZE</a></td></tr>
<tr class="memdesc:a6b93563370dd18a3e6cf83bca149a661"><td class="mdescLeft">&#160;</td><td class="mdescRight">Size of the chunk of the data loaded at once (default: 50,000 data points)  <a href="structparameters.html#a6b93563370dd18a3e6cf83bca149a661">More...</a><br /></td></tr>
<tr class="separator:a6b93563370dd18a3e6cf83bca149a661"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95e3c939fd0f1f555d850fabc3a46b4d"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a95e3c939fd0f1f555d850fabc3a46b4d">CHUNK_WEIGHT</a></td></tr>
<tr class="memdesc:a95e3c939fd0f1f555d850fabc3a46b4d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Size of chunk of <a class="el" href="classbudgeted_vector.html">budgetedVector</a> weight (whole vector is split into smaller parts) (default: 1,000)  <a href="structparameters.html#a95e3c939fd0f1f555d850fabc3a46b4d">More...</a><br /></td></tr>
<tr class="separator:a95e3c939fd0f1f555d850fabc3a46b4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5fda4549213d6167b5be0b5412079026"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a5fda4549213d6167b5be0b5412079026">KERNEL</a></td></tr>
<tr class="memdesc:a5fda4549213d6167b5be0b5412079026"><td class="mdescLeft">&#160;</td><td class="mdescRight">Choose the kernel function for kernel-based algorithms, 0 - Gaussian kernel, 1 - polynomial kernel, 2 - linear kernel (default: 0)  <a href="structparameters.html#a5fda4549213d6167b5be0b5412079026">More...</a><br /></td></tr>
<tr class="separator:a5fda4549213d6167b5be0b5412079026"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f2db6d4c67d4189b7cc2b92cc83b7e0"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a0f2db6d4c67d4189b7cc2b92cc83b7e0">BUDGET_SIZE</a></td></tr>
<tr class="memdesc:a0f2db6d4c67d4189b7cc2b92cc83b7e0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Maximum number of weight per class of AMM algorithms, OR size of the budget of BSGD algorithm, OR number of landmark points in LLSVM algorithm (default: 50)  <a href="structparameters.html#a0f2db6d4c67d4189b7cc2b92cc83b7e0">More...</a><br /></td></tr>
<tr class="separator:a0f2db6d4c67d4189b7cc2b92cc83b7e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b3c95d90fc21237284ff217b36bc5d7"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a0b3c95d90fc21237284ff217b36bc5d7">K_MEANS_ITERS</a></td></tr>
<tr class="memdesc:a0b3c95d90fc21237284ff217b36bc5d7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of k-means iterations in initialization of LLSVM algorithm (default: 10)  <a href="structparameters.html#a0b3c95d90fc21237284ff217b36bc5d7">More...</a><br /></td></tr>
<tr class="separator:a0b3c95d90fc21237284ff217b36bc5d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6e54785c714946c5b27072fbf6b3fbf"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#ad6e54785c714946c5b27072fbf6b3fbf">MAINTENANCE_SAMPLING_STRATEGY</a></td></tr>
<tr class="memdesc:ad6e54785c714946c5b27072fbf6b3fbf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Budget maintenance strategy of BSGD algorithm, 0 - random removal; 1 - merging, OR type of landmark points sampling in LLSVM algorithm, 0 - random; 1 - k-means; 2 - k-medoids (default: 0)  <a href="structparameters.html#ad6e54785c714946c5b27072fbf6b3fbf">More...</a><br /></td></tr>
<tr class="separator:ad6e54785c714946c5b27072fbf6b3fbf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa3c969ce30b1b163bfa1ff0d6b6ed0dd"><td class="memItemLeft" align="right" valign="top">unsigned int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#aa3c969ce30b1b163bfa1ff0d6b6ed0dd">VERY_SPARSE_DATA</a></td></tr>
<tr class="memdesc:aa3c969ce30b1b163bfa1ff0d6b6ed0dd"><td class="mdescLeft">&#160;</td><td class="mdescRight">User set parameter, if a user believes the data is very sparse this parameters can be set to 0/1, where 1 - very sparse data; 0 - not very sparse data (default: see long description)  <a href="structparameters.html#aa3c969ce30b1b163bfa1ff0d6b6ed0dd">More...</a><br /></td></tr>
<tr class="separator:aa3c969ce30b1b163bfa1ff0d6b6ed0dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac91ace5a347d663cde54542f1549f6be"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#ac91ace5a347d663cde54542f1549f6be">C_PARAM</a></td></tr>
<tr class="memdesc:ac91ace5a347d663cde54542f1549f6be"><td class="mdescLeft">&#160;</td><td class="mdescRight">Weight pruning parameter c of AMM algorithms (default: 10.0)  <a href="structparameters.html#ac91ace5a347d663cde54542f1549f6be">More...</a><br /></td></tr>
<tr class="separator:ac91ace5a347d663cde54542f1549f6be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a733ba063d25a5eaa54f56507f9199859"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a733ba063d25a5eaa54f56507f9199859">BIAS_TERM</a></td></tr>
<tr class="memdesc:a733ba063d25a5eaa54f56507f9199859"><td class="mdescLeft">&#160;</td><td class="mdescRight">Bias term of AMM batch, AMM online, and PEGASOS algorithms (default: 1.0)  <a href="structparameters.html#a733ba063d25a5eaa54f56507f9199859">More...</a><br /></td></tr>
<tr class="separator:a733ba063d25a5eaa54f56507f9199859"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26ac9c2de68d48076198b680f81a4cef"><td class="memItemLeft" align="right" valign="top"><a id="a26ac9c2de68d48076198b680f81a4cef"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a26ac9c2de68d48076198b680f81a4cef">KERNEL_GAMMA_PARAM</a></td></tr>
<tr class="memdesc:a26ac9c2de68d48076198b680f81a4cef"><td class="mdescLeft">&#160;</td><td class="mdescRight">Kernel width parameter in Gaussian kernel exp(-0.5 * KERNEL_GAMMA_PARAM * ||x - y||^2) (default: 1/DIMENSIONALITY) <br /></td></tr>
<tr class="separator:a26ac9c2de68d48076198b680f81a4cef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa29e85634bc35d206de35cc740ba40fc"><td class="memItemLeft" align="right" valign="top"><a id="aa29e85634bc35d206de35cc740ba40fc"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#aa29e85634bc35d206de35cc740ba40fc">KERNEL_DEGREE_PARAM</a></td></tr>
<tr class="memdesc:aa29e85634bc35d206de35cc740ba40fc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Degree of polynomial kernel (x^T * y + KERNEL_COEF_PARAM)^KERNEL_DEGREE_PARAM, OR slope parameter of sigmoid kernel tanh(KERNEL_DEGREE_PARAM * x^T * y + KERNEL_COEF_PARAM) (default: 2) <br /></td></tr>
<tr class="separator:aa29e85634bc35d206de35cc740ba40fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e7018fee58e3d2c63acfdc73dd21d9b"><td class="memItemLeft" align="right" valign="top"><a id="a8e7018fee58e3d2c63acfdc73dd21d9b"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a8e7018fee58e3d2c63acfdc73dd21d9b">KERNEL_COEF_PARAM</a></td></tr>
<tr class="memdesc:a8e7018fee58e3d2c63acfdc73dd21d9b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Coefficient of polynomial kernel (x^T * y + KERNEL_COEF_PARAM)^KERNEL_DEGREE_PARAM, or intercept of sigmoid kernel tanh(KERNEL_DEGREE_PARAM * x^T * y + KERNEL_COEF_PARAM) (default: 1) <br /></td></tr>
<tr class="separator:a8e7018fee58e3d2c63acfdc73dd21d9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f7c09ba0b73c6591486b425264f57e2"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a6f7c09ba0b73c6591486b425264f57e2">LAMBDA_PARAM</a></td></tr>
<tr class="memdesc:a6f7c09ba0b73c6591486b425264f57e2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Lambda regularization parameter; higher values result in more regularization (default: 0.0001)  <a href="structparameters.html#a6f7c09ba0b73c6591486b425264f57e2">More...</a><br /></td></tr>
<tr class="separator:a6f7c09ba0b73c6591486b425264f57e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd73a3d0c007604ba01d09e822f278c4"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#acd73a3d0c007604ba01d09e822f278c4">CLONE_PROBABILITY</a></td></tr>
<tr class="memdesc:acd73a3d0c007604ba01d09e822f278c4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Probability of cloning a true-class weight when a misclassification happens (default: 0.0)  <a href="structparameters.html#acd73a3d0c007604ba01d09e822f278c4">More...</a><br /></td></tr>
<tr class="separator:acd73a3d0c007604ba01d09e822f278c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7f8a5452058c3fce309605240c2e160"><td class="memItemLeft" align="right" valign="top"><a id="ac7f8a5452058c3fce309605240c2e160"></a>
double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#ac7f8a5452058c3fce309605240c2e160">CLONE_PROBABILITY_DECAY</a></td></tr>
<tr class="memdesc:ac7f8a5452058c3fce309605240c2e160"><td class="mdescLeft">&#160;</td><td class="mdescRight">Value between 0 and 1 by which <a class="el" href="structparameters.html#acd73a3d0c007604ba01d09e822f278c4">CLONE_PROBABILITY</a> is decayed after successful weight duplication (default: 0.99) <br /></td></tr>
<tr class="separator:ac7f8a5452058c3fce309605240c2e160"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aacfa57cf0945ef0f82312b5d8962b19a"><td class="memItemLeft" align="right" valign="top"><a id="aacfa57cf0945ef0f82312b5d8962b19a"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#aacfa57cf0945ef0f82312b5d8962b19a">VERBOSE</a></td></tr>
<tr class="memdesc:aacfa57cf0945ef0f82312b5d8962b19a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Print verbose output during algorithm execution, 1 - verbose output; 0 - quiet (default: 0) <br /></td></tr>
<tr class="separator:aacfa57cf0945ef0f82312b5d8962b19a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afaf203a5df82dfb562eb3d96b085c9d6"><td class="memItemLeft" align="right" valign="top"><a id="afaf203a5df82dfb562eb3d96b085c9d6"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#afaf203a5df82dfb562eb3d96b085c9d6">RANDOMIZE</a></td></tr>
<tr class="memdesc:afaf203a5df82dfb562eb3d96b085c9d6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Randomize (i.e., shuffle) the training data, 1 - randomization on; 0 - randomization off (default: 1) <br /></td></tr>
<tr class="separator:afaf203a5df82dfb562eb3d96b085c9d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c5985fd56f0d7ffd796b5d09f5752d9"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structparameters.html#a1c5985fd56f0d7ffd796b5d09f5752d9">OUTPUT_SCORES</a></td></tr>
<tr class="memdesc:a1c5985fd56f0d7ffd796b5d09f5752d9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Output the winning class scores, in addition to class predictions, 1 - output class scores; 0 - output without class scores (default: 0)  <a href="structparameters.html#a1c5985fd56f0d7ffd796b5d09f5752d9">More...</a><br /></td></tr>
<tr class="separator:a1c5985fd56f0d7ffd796b5d09f5752d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Structure holds the parameters of the implemented algorithms. </p>
<p>Structure holds the parameters of the implemented algorithms. If needed, the default parameters for each algorithm can be manually modified here. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00109">109</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a4950eb95f9a5ab221bb7f6b040546ee8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4950eb95f9a5ab221bb7f6b040546ee8">&#9670;&nbsp;</a></span>updateVerySparseDataParameter()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void parameters::updateVerySparseDataParameter </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>dataSparsity</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>If <a class="el" href="structparameters.html#aa3c969ce30b1b163bfa1ff0d6b6ed0dd">VERY_SPARSE_DATA</a> parameter was not set by a user, this function sets this parameter according to the sparsity of the loaded data. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">dataSparsity</td><td>The sparsity of the loaded data set.</td></tr>
  </table>
  </dd>
</dl>
<p>When computing the kernels between support vectors/hyperplanes kept in the available budget in <a class="el" href="classbudgeted_vector.html" title="Class which handles high-dimensional vectors.">budgetedVector</a> objects on one side, and the incoming data points on the other, we have two options: (1) we can either do the computations directly between the support vectors and data points that are stored in <a class="el" href="classbudgeted_data.html" title="Class which handles manipulation of large data sets that cannot be fully loaded to memory (using a da...">budgetedData</a>; or (2) we can do the computations between the support vectors and data points that are in the intermediate step stored in the <a class="el" href="classbudgeted_vector.html" title="Class which handles high-dimensional vectors.">budgetedVector</a> object. When the data is very sparse option (1) is faster, as there is very small number of non-zero features that affects the speed of the computations, and the overhead of creating the <a class="el" href="classbudgeted_vector.html" title="Class which handles high-dimensional vectors.">budgetedVector</a> instance might prove too costly. On the other hand, when the data is not too sparse, then it might prove faster to first create <a class="el" href="classbudgeted_vector.html" title="Class which handles high-dimensional vectors.">budgetedVector</a> that will hold the incoming data point, and only then do the kernel computations. The reason is partly in a slow modulus operation that is used in the case (1) (please refer to the implementation of linear and Gaussian kernels to see how it was coded. </p><dl class="section see"><dt>See also</dt><dd><a class="el" href="structparameters.html#aa3c969ce30b1b163bfa1ff0d6b6ed0dd" title="User set parameter, if a user believes the data is very sparse this parameters can be set to 0/1,...">VERY_SPARSE_DATA</a>, <a class="el" href="classbudgeted_vector.html#aecb57e663fd088c08418dd38fcbe9782" title="Computes linear kernel between this budgetedVector vector and another vector stored in budgetedData.">budgetedVector::linearKernel(unsigned int, budgetedData*, parameters*)</a>, <a class="el" href="classbudgeted_vector.html#ab9a30fb0a0c8a73eee04e6710165845f" title="Computes linear kernel between this budgetedVector vector and another vector stored in budgetedVector...">budgetedVector::linearKernel(budgetedVector*)</a>, <a class="el" href="classbudgeted_vector.html#a8d9cd5eb6361e64010e9180e3d2caf27" title="Computes Gaussian kernel between this budgetedVector vector and another vector from input data stored...">budgetedVector::gaussianKernel(unsigned int, budgetedData*, parameters*, long double)</a>, <a class="el" href="classbudgeted_vector.html#afbd37a97c4def119f81596074eb99870" title="Computes Gaussian kernel between this budgetedVector vector and another vector stored in budgetedVect...">budgetedVector::gaussianKernel(budgetedVector*, parameters*)</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00314">314</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>
<div class="fragment"><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;    {</div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;        <span class="comment">// if the parameter is already set then just return and change nothing; it can be that it was set by a user</span></div>
<div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;        <span class="comment">//  or it was already set when the earlier data chunks were loaded</span></div>
<div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;        <span class="keywordflow">if</span> ((<a class="code" href="structparameters.html#aa3c969ce30b1b163bfa1ff0d6b6ed0dd">VERY_SPARSE_DATA</a> == 0) || (<a class="code" href="structparameters.html#aa3c969ce30b1b163bfa1ff0d6b6ed0dd">VERY_SPARSE_DATA</a> == 1))</div>
<div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;            <span class="keywordflow">return</span>;</div>
<div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;        </div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;        <span class="comment">// if the sparsity is less than 5%, then we say that we are working with very sparse data</span></div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;        <span class="keywordflow">if</span> (dataSparsity &lt; 5.0)</div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;            <a class="code" href="structparameters.html#aa3c969ce30b1b163bfa1ff0d6b6ed0dd">VERY_SPARSE_DATA</a> = 1;</div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;        <span class="keywordflow">else</span></div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;            <a class="code" href="structparameters.html#aa3c969ce30b1b163bfa1ff0d6b6ed0dd">VERY_SPARSE_DATA</a> = 0;</div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;    };</div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a733ba063d25a5eaa54f56507f9199859"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a733ba063d25a5eaa54f56507f9199859">&#9670;&nbsp;</a></span>BIAS_TERM</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double parameters::BIAS_TERM</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Bias term of AMM batch, AMM online, and PEGASOS algorithms (default: 1.0) </p>
<p>If the parameter is non-zero, a bias, or intercept term, is added to the data set as an additional feature. The value of this additional feature is equal to BIAS_TERM. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00263">263</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="a0f2db6d4c67d4189b7cc2b92cc83b7e0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f2db6d4c67d4189b7cc2b92cc83b7e0">&#9670;&nbsp;</a></span>BUDGET_SIZE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int parameters::BUDGET_SIZE</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Maximum number of weight per class of AMM algorithms, OR size of the budget of BSGD algorithm, OR number of landmark points in LLSVM algorithm (default: 50) </p>
<ul>
<li>AMM: As the number of weights in AMM algorithms is infinite, we can set the limit on the number of non-zero weights that can be stored in memory. This can be done in order to avoid memory-related problems. Once the limit is reached, we do not allow creation of new non-zero weights until some get pruned.</li>
<li>BSGD: Maximum number of support vectors that can be stored. After the budget is exceeded, <a class="el" href="structparameters.html#ad6e54785c714946c5b27072fbf6b3fbf">MAINTENANCE_SAMPLING_STRATEGY</a> specifies how the number of support vectors is kept limited.</li>
<li>LLSVM: In addition, it also specifies the number of landmark points in LLSVM algorithm, that are used to represent the data set in lower-dimensional space using the Nystrom method. </li>
</ul>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00262">262</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="ac91ace5a347d663cde54542f1549f6be"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac91ace5a347d663cde54542f1549f6be">&#9670;&nbsp;</a></span>C_PARAM</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double parameters::C_PARAM</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Weight pruning parameter c of AMM algorithms (default: 10.0) </p>
<p>In order to reduce the complexity of the learned model, which directly improves generalization of the model as shown in the original AMM paper, pruning of small non-zero weights is performed. C_PARAM specifies the aggressiveness of weight pruning, where larger value results in pruning of more weights. More specifically, we sort the weights by their L2-norms, and then prune from the smallest toward larger weight until the cumulative weight norm exceeds value of C_PARAM. Frequency of pruning is controlled by <a class="el" href="structparameters.html#ae071568a10354aa235e31ff10fd042d6">K_PARAM</a> parameter. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00263">263</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="a6b93563370dd18a3e6cf83bca149a661"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b93563370dd18a3e6cf83bca149a661">&#9670;&nbsp;</a></span>CHUNK_SIZE</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int parameters::CHUNK_SIZE</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Size of the chunk of the data loaded at once (default: 50,000 data points) </p>
<p>While <a class="el" href="structparameters.html#a95e3c939fd0f1f555d850fabc3a46b4d">CHUNK_WEIGHT</a> helps when one is working with high-dimensional data, this parameter helps when working with large data with many instances. If the data set is very large and can not fit into memory, we can then load only a small part of it (called <em>data chunk</em>), that is processed before being discarded to make room for the next chunk. Therefore, we load only a smaller part of the large data set, with size of this chunk specified by this parameter. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00261">261</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="a95e3c939fd0f1f555d850fabc3a46b4d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a95e3c939fd0f1f555d850fabc3a46b4d">&#9670;&nbsp;</a></span>CHUNK_WEIGHT</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int parameters::CHUNK_WEIGHT</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Size of chunk of <a class="el" href="classbudgeted_vector.html">budgetedVector</a> weight (whole vector is split into smaller parts) (default: 1,000) </p>
<p>While <a class="el" href="structparameters.html#a6b93563370dd18a3e6cf83bca149a661">CHUNK_SIZE</a> helps when one is working with large data with many data points, this parameter helps when working with high-dimensional data. When the data is sparse, then we do not have to explicitly store every feature as most of them are equal to 0. One option is simply to follow LIBSVM format, and store a vector in two linked lists, one holding feature index and the other holding the corresponding feature value. However, we found that accessing this data structure can become prohibitively slow, as for high-dimensional data weights can become less sparse than the original data due to the weight update process. For example, when we want to update a specific feature during gradient descent training we would like to do it very quickly, most preferably we would like to have random access to the element of the weight vector that will be updated. We address this by storing a <br  />
 vector into linked list, where each element of the linked list, called <em>weight chunk</em>, holding a subset of features. For example, the first chunk would hold features indexed from 1 to CHUNK_SIZE, the second would hold features indexed from CHUNK_SIZE+1 to 2*CHUNK_SIZE, and so on. If all elements of a weight chunk are zero, we do not allocate memory for that array. In our experience, this significantly improved the training and testing time on truly high-dimensional data, such as on URL data set with more than 3.2 million features. If <a class="el" href="structparameters.html#a95e3c939fd0f1f555d850fabc3a46b4d">CHUNK_WEIGHT</a> is equal to 1, we obtain the LIBSVM-type representation. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00261">261</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="acd73a3d0c007604ba01d09e822f278c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acd73a3d0c007604ba01d09e822f278c4">&#9670;&nbsp;</a></span>CLONE_PROBABILITY</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool parameters::CLONE_PROBABILITY</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Probability of cloning a true-class weight when a misclassification happens (default: 0.0) </p>
<p>When a misclassification occurs both the true-class and the incorrect-class weights are updated. However, there is also an option to duplicate the true-class weight before the update step, leading to better performance on highly-nonlinear problems. This is done by throwing a biased coin with this probability and generating a duplicate weight if the throw is successful. Note however that this probability is decreased every time a weight is successfully duplicated, controlled by the parameter <a class="el" href="structparameters.html#ac7f8a5452058c3fce309605240c2e160">CLONE_PROBABILITY_DECAY</a>. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00263">263</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="a9070068c869e6665c4fe04bd6a8d1b15"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9070068c869e6665c4fe04bd6a8d1b15">&#9670;&nbsp;</a></span>DIMENSION</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int parameters::DIMENSION</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Dimensionality of the classification problem, MUST be set by a user (default: 0) </p>
<p>Although the dimensionality of the data set can be found from the training data set during loading, we ask a user to specify it beforehand, as it is usually a known parameter. The reason why we require this as an input is to speed up processing of the data, since the emphasis of the software is on speeding up the training of classification algorithm on large data, and this little piece of information can help avoid unnecessary bookkeeping tasks. More specifically, the parameter is important for memory management of <a class="el" href="classbudgeted_vector.html">budgetedVector</a>, where it is used to find how many weight chunks of size <a class="el" href="structparameters.html#a95e3c939fd0f1f555d850fabc3a46b4d">CHUNK_WEIGHT</a> are needed to represent the data.</p>
<p>However, in the case of Matlab interface, it is not required to manually set this parameter as it is easily found by reading the dimensions of the Matlab structure holding the data set. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00261">261</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="a0b3c95d90fc21237284ff217b36bc5d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b3c95d90fc21237284ff217b36bc5d7">&#9670;&nbsp;</a></span>K_MEANS_ITERS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int parameters::K_MEANS_ITERS</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Number of k-means iterations in initialization of LLSVM algorithm (default: 10) </p>
<p>In order to find better lower-dimensional representation of the data set using Nystrom method, k-means can be used to improve the choice of landmark points. Unlike in random sampling of landmark points from the data set, cluster centers of k-means will represent <a class="el" href="structparameters.html#a0f2db6d4c67d4189b7cc2b92cc83b7e0">BUDGET_SIZE</a> points used for the Nystrom method. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00262">262</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="ae071568a10354aa235e31ff10fd042d6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae071568a10354aa235e31ff10fd042d6">&#9670;&nbsp;</a></span>K_PARAM</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int parameters::K_PARAM</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Frequency k of weight pruning of AMM algorithms (default: 10,000 iterations) </p>
<p>In order to reduce the complexity of the learned model, which directly improves generalization of the model as shown in the AMM paper, pruning of small non-zero weights is performed. <a class="el" href="structparameters.html#ae071568a10354aa235e31ff10fd042d6">K_PARAM</a> specifies the frequency of weight pruning, i.e., after how many iterations we perform the pruning step. Aggressiveness of pruning is controlled by <a class="el" href="structparameters.html#ac91ace5a347d663cde54542f1549f6be">C_PARAM</a> parameter. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00261">261</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="a5fda4549213d6167b5be0b5412079026"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5fda4549213d6167b5be0b5412079026">&#9670;&nbsp;</a></span>KERNEL</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int parameters::KERNEL</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Choose the kernel function for kernel-based algorithms, 0 - Gaussian kernel, 1 - polynomial kernel, 2 - linear kernel (default: 0) </p>
<p>The parameter indicates which kernel function is used in kernel-based algorithms. Note that there is no such choice for AMM. The following kernels are available for two input data points x and y:</p>
<ul>
<li>Gaussian: K(x, y) = exp(-0.5 * <a class="el" href="structparameters.html#a26ac9c2de68d48076198b680f81a4cef">KERNEL_GAMMA_PARAM</a> * ||x - y||^2)</li>
<li>Exponential: K(x, y) = exp(-0.5 * <a class="el" href="structparameters.html#a26ac9c2de68d48076198b680f81a4cef">KERNEL_GAMMA_PARAM</a> * ||x - y||)</li>
<li>Polynomial: K(x, y) = (x^T * y + <a class="el" href="structparameters.html#a8e7018fee58e3d2c63acfdc73dd21d9b">KERNEL_COEF_PARAM</a>)^<a class="el" href="structparameters.html#aa29e85634bc35d206de35cc740ba40fc">KERNEL_DEGREE_PARAM</a></li>
<li>Linear: K(x, y) = (x^T * y)</li>
<li>Sigmoid: K(x, y) = tanh(<a class="el" href="structparameters.html#aa29e85634bc35d206de35cc740ba40fc">KERNEL_DEGREE_PARAM</a> * x^T * y + <a class="el" href="structparameters.html#a8e7018fee58e3d2c63acfdc73dd21d9b">KERNEL_COEF_PARAM</a>)</li>
<li>User-defined: To add your kernel function please open file '<a class="el" href="budgeted_s_v_m_8cpp_source.html">src/budgetedSVM.cpp</a>' and modify two userDefinedKernel() methods located there. </li>
</ul>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00261">261</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="a6f7c09ba0b73c6591486b425264f57e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6f7c09ba0b73c6591486b425264f57e2">&#9670;&nbsp;</a></span>LAMBDA_PARAM</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double parameters::LAMBDA_PARAM</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Lambda regularization parameter; higher values result in more regularization (default: 0.0001) </p>
<p>The parameter defines the level of model regularization, where larger values result in less complex model (i.e., more regularized model). The parameter is used in all BudgetedSVM algorithms with the same effect, and decreasing the value of this parameter leads to more overfitting on the training set. When compared to C parameter used in LibLinear solver which is employed in LLSVM algorithm, LAMBDA_PARAM is exactly reciprocal (i.e., LAMBDA_PARAM = 1 / C). </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00263">263</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="ad6e54785c714946c5b27072fbf6b3fbf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad6e54785c714946c5b27072fbf6b3fbf">&#9670;&nbsp;</a></span>MAINTENANCE_SAMPLING_STRATEGY</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int parameters::MAINTENANCE_SAMPLING_STRATEGY</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Budget maintenance strategy of BSGD algorithm, 0 - random removal; 1 - merging, OR type of landmark points sampling in LLSVM algorithm, 0 - random; 1 - k-means; 2 - k-medoids (default: 0) </p>
<ul>
<li>BSGD: Whenever a number of support vectors in BSGD algorithm exceeds <a class="el" href="structparameters.html#a0f2db6d4c67d4189b7cc2b92cc83b7e0">BUDGET_SIZE</a>, one of the following budget maintenance steps is performed, depending on the value of the MAINTENANCE_SAMPLING_STRATEGY parameter<ul>
<li>0 - deleting random support vector to maintain the budget</li>
<li>1 - take two support vectors and merging them into one. The new, merged support vector is located on the straight line connecting the two existing support vectors; where exactly on the line is explained in <em>computeKmax()</em> function from <em>bsdg.cpp</em> file. Then, the two existing support vectors are deleted and the merged vector is inserted in the budget. Note that kernel function for BSGD when merging strategy is chosen defaults to Gaussian kernel. (default setting)</li>
</ul>
</li>
<li>LLSVM: Specifies how the landmark points, used to represent the data set in lower-dimensional space using the Nystrom method, are chosen.<ul>
<li>0 - landmark points are randomly sampled from the the first loaded data chunk</li>
<li>1 - landmark points will be cluster centers after running k-means on the first loaded data chunk (default setting)</li>
<li>2 - landmark points will be cluster medoids after running k-medoids on the first loaded data chunk </li>
</ul>
</li>
</ul>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00262">262</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="a7a5d9f4f2ac435cb56ecc0bd879977d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7a5d9f4f2ac435cb56ecc0bd879977d5">&#9670;&nbsp;</a></span>NUM_EPOCHS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int parameters::NUM_EPOCHS</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Number of training epochs (default: 5) </p>
<p>Number of times the data set is seen by the training procedure, each time randomly reshuffled. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00261">261</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="a7b41d4a23975df18a08aba2869c723ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b41d4a23975df18a08aba2869c723ab">&#9670;&nbsp;</a></span>NUM_SUBEPOCHS</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int parameters::NUM_SUBEPOCHS</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Number of training subepochs of AMM batch algorithm (default: 1) </p>
<p>AMM batch has an option to reassign data points to weights several times during one epoch. In the most extreme case, if <a class="el" href="structparameters.html#a7b41d4a23975df18a08aba2869c723ab">NUM_SUBEPOCHS</a> is equal to the size of the data set, we obtain AMM online algorithm. This parameter specifies how many times we reassign points to weights within a single epoch. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00261">261</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="a1c5985fd56f0d7ffd796b5d09f5752d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c5985fd56f0d7ffd796b5d09f5752d9">&#9670;&nbsp;</a></span>OUTPUT_SCORES</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool parameters::OUTPUT_SCORES</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Output the winning class scores, in addition to class predictions, 1 - output class scores; 0 - output without class scores (default: 0) </p>
<p>If this parameter is set, the output scores should be interpreted as follows. For LLSVM the score represents the distance of test example from the separating hyperplane; for AMM and BSGD this score represents difference between the winning-class score and the score of a class that had the second-best score. </p>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00264">264</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<a id="aa3c969ce30b1b163bfa1ff0d6b6ed0dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa3c969ce30b1b163bfa1ff0d6b6ed0dd">&#9670;&nbsp;</a></span>VERY_SPARSE_DATA</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned int parameters::VERY_SPARSE_DATA</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>User set parameter, if a user believes the data is very sparse this parameters can be set to 0/1, where 1 - very sparse data; 0 - not very sparse data (default: see long description) </p>
<p>When computing the kernels between support vectors/hyperplanes kept in the available budget in <a class="el" href="classbudgeted_vector.html" title="Class which handles high-dimensional vectors.">budgetedVector</a> objects on one side, and the incoming data points on the other, we have two options: (1) we can either do the computations directly between the support vectors and data points that are stored in <a class="el" href="classbudgeted_data.html" title="Class which handles manipulation of large data sets that cannot be fully loaded to memory (using a da...">budgetedData</a>; or (2) we can do the computations between the support vectors and data points that are in the intermediate step stored in the <a class="el" href="classbudgeted_vector.html" title="Class which handles high-dimensional vectors.">budgetedVector</a> object. When the data is very sparse option (1) is faster, as there is very small number of non-zero features that affects the speed of the computations, and the overhead of creating the <a class="el" href="classbudgeted_vector.html" title="Class which handles high-dimensional vectors.">budgetedVector</a> instance might prove too costly. On the other hand, when the data is not too sparse, then it might prove faster to first create <a class="el" href="classbudgeted_vector.html" title="Class which handles high-dimensional vectors.">budgetedVector</a> that will hold the incoming data point, and only then do the kernel computations. The reason is partly in a slow modulus operation that is used in the case (1) (please refer to the implementation of linear and Gaussian kernels to see how it was coded).</p>
<p>If a user does not manually set this parameter to 0 (i.e., instructs the toolbox to compute kernels as in case (1)) or 1 (i.e., compute kernels as in case (2)), the default setting will be 0 if the sparsity of the loaded data is less than 5% (i.e., less than 5% of the features are non-zero on average), otherwise it will default to 1. For this default behavior that is adaptive to the found data sparsity a developer can set this parameter to anything other than 0 or 1. For more details, please see the train and test functions of the implemented algorithms, and look for code parts where VERY_SPARSE_DATA appears. </p><dl class="section see"><dt>See also</dt><dd><a class="el" href="structparameters.html#a4950eb95f9a5ab221bb7f6b040546ee8" title="If VERY_SPARSE_DATA parameter was not set by a user, this function sets this parameter according to t...">updateVerySparseDataParameter()</a>, <a class="el" href="classbudgeted_vector.html#aecb57e663fd088c08418dd38fcbe9782" title="Computes linear kernel between this budgetedVector vector and another vector stored in budgetedData.">budgetedVector::linearKernel(unsigned int, budgetedData*, parameters*)</a>, <a class="el" href="classbudgeted_vector.html#ab9a30fb0a0c8a73eee04e6710165845f" title="Computes linear kernel between this budgetedVector vector and another vector stored in budgetedVector...">budgetedVector::linearKernel(budgetedVector*)</a>, <a class="el" href="classbudgeted_vector.html#a8d9cd5eb6361e64010e9180e3d2caf27" title="Computes Gaussian kernel between this budgetedVector vector and another vector from input data stored...">budgetedVector::gaussianKernel(unsigned int, budgetedData*, parameters*, long double)</a>, <a class="el" href="classbudgeted_vector.html#afbd37a97c4def119f81596074eb99870" title="Computes Gaussian kernel between this budgetedVector vector and another vector stored in budgetedVect...">budgetedVector::gaussianKernel(budgetedVector*, parameters*)</a> </dd></dl>

<p class="definition">Definition at line <a class="el" href="budgeted_s_v_m_8h_source.html#l00262">262</a> of file <a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a>.</p>

</div>
</div>
<hr/>The documentation for this struct was generated from the following file:<ul>
<li>C:/Users/Nemanja/Documents/Yahoo/Downloads/BudgetedSVM/src/<a class="el" href="budgeted_s_v_m_8h_source.html">budgetedSVM.h</a></li>
</ul>
</div><!-- contents -->
<div class="ttc" id="astructparameters_html_aa3c969ce30b1b163bfa1ff0d6b6ed0dd"><div class="ttname"><a href="structparameters.html#aa3c969ce30b1b163bfa1ff0d6b6ed0dd">parameters::VERY_SPARSE_DATA</a></div><div class="ttdeci">unsigned int VERY_SPARSE_DATA</div><div class="ttdoc">User set parameter, if a user believes the data is very sparse this parameters can be set to 0/1,...</div><div class="ttdef"><b>Definition:</b> <a href="budgeted_s_v_m_8h_source.html#l00262">budgetedSVM.h:262</a></div></div>
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Sun Jun 28 2020 02:22:51 for BudgetedSVM by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.18
</small></address>
</body>
</html>
